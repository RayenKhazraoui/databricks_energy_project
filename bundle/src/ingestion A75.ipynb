{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a774a04c-bca5-4639-b8cd-702ecfe5e4a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog data;\n",
    "use schema bronze;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6014cc6-4c20-48fa-8e4c-66c1d2b9eca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE table if not exists data.bronze.bronze_A75 (\n",
    "  current_timestamp TIMESTAMP,\n",
    "  filename STRING,\n",
    "  xml_string STRING\n",
    ")\n",
    "USING DELTA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba22d960-8156-4fdb-a96f-e88d54fbfa4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import current_timestamp, col\n",
    "\n",
    "# Define the source path\n",
    "source_path = \"/Volumes/source/source_schema/source_volume/A75\"\n",
    "\n",
    "# Read XML files as binary/text using Auto Loader\n",
    "df = (spark.readStream\n",
    "  .format(\"cloudFiles\")\n",
    "  .option(\"cloudFiles.format\", \"binaryFile\")  # Read files as binary\n",
    "  .option(\"pathGlobFilter\", \"*.xml\")  # Filter for XML files only\n",
    "  .option(\"cloudFiles.useNotifications\", \"false\")  # Use directory listing for volumes\n",
    "  .load(source_path)\n",
    ")\n",
    "\n",
    "# Transform: extract filename and convert binary content to string\n",
    "df_transformed = df.select(\n",
    "  current_timestamp().alias(\"current_timestamp\"),\n",
    "  col(\"_metadata.file_path\").alias(\"filename\"),\n",
    "  col(\"content\").cast(\"string\").alias(\"xml_string\")\n",
    ")\n",
    "\n",
    "# Write to bronze table using Auto Loader streaming\n",
    "query = (df_transformed.writeStream\n",
    "  .format(\"delta\")\n",
    "  .outputMode(\"append\")\n",
    "  .option(\"checkpointLocation\", \"/Volumes/source/source_schema/source_volume/checkpoints/bronze_A16\")\n",
    "  .trigger(availableNow=True)  # Process all available files then stop\n",
    "  .toTable(\"data.bronze.bronze_A75\")\n",
    ")\n",
    "\n",
    "# Wait for the stream to finish processing\n",
    "query.awaitTermination()\n",
    "\n",
    "print(\"Auto Loader ingestion completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c070d7bd-5c19-4e76-9dc1-c39735a1c675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6287989430658168,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestion A75",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
